# (PART) Basic Tensor Operations {-}

# Tensors

We describe the most important PyTorch methods in this chapter.


```{r}
library(rTorch)

```

## Tensor data types

```{r}
# Default data type
torch$tensor(list(1.2, 3))$dtype  # default for floating point is torch.float32
```

```{r}
# change default data type to float64
torch$set_default_dtype(torch$float64)
torch$tensor(list(1.2, 3))$dtype         # a new floating point tensor
```


There are five major type of Tensors in PyTorch

```{r}
library(rTorch)

byte    <- torch$ByteTensor(3L, 3L)
float   <- torch$FloatTensor(3L, 3L)
double  <- torch$DoubleTensor(3L, 3L)
long    <- torch$LongTensor(3L, 3L)
boolean <- torch$BoolTensor(5L, 5L)

message("byte tensor")
byte

message("float tensor")
float

message("double")
double

message("long")
long

message("boolean")
boolean
```

A 4D tensor like in MNIST hand-written digits recognition dataset:

```{r}
mnist_4d <- torch$FloatTensor(60000L, 3L, 28L, 28L)

message("size")
mnist_4d$size()

message("length")
length(mnist_4d)


message("shape, like in numpy")
mnist_4d$shape

message("number of elements")
mnist_4d$numel()
```

A 3D tensor:

```{r}
ft3d <- torch$FloatTensor(4L, 3L, 2L)
ft3d
```


## Arithmetic of tensors

### Add tensors

```{r}
# add a scalar to a tensor
# 3x5 matrix uniformly distributed between 0 and 1
mat0 <- torch$FloatTensor(3L, 5L)$uniform_(0L, 1L)
mat0 + 0.1
```

> The expression ``tensor.index(m)`` is equivalent to ``tensor[m]``.

Add an element of tensor to a tensor:

```{r}
# fill a 3x5 matrix with 0.1
mat1 <- torch$FloatTensor(3L, 5L)$uniform_(0.1, 0.1)
# a vector with all ones
mat2 <- torch$FloatTensor(5L)$uniform_(1, 1)
mat1[1, 1] + mat2
```

```{r}
# add two tensors
mat1 + mat0
```

Add two tensors using the function `add()`:
```{r}
# PyTorch add two tensors
x = torch$rand(5L, 4L)
y = torch$rand(5L, 4L)

print(x$add(y))
```

Add two tensors using the generic `+`:
```{r}
print(x + y)
```


### Multiply a tensor by a scalar

```{r}
# Multiply tensor by scalar
tensor = torch$ones(4L, dtype=torch$float64)
scalar = np$float64(4.321)
print(scalar)
print(torch$scalar_tensor(scalar))
```

Multiply two tensors using the function `mul`:
```{r}
(prod = torch$mul(tensor, torch$scalar_tensor(scalar)))
```


Short version using generics
```{r}
(prod = tensor * scalar)
```



## NumPy and PyTorch
`numpy` has been made available as a module in `rTorch`. We can call functions from `numpy` refrerring to it as `np$_a_function`. Examples:

```{r}
# a 2D numpy array  
syn0 <- np$random$rand(3L, 5L)
print(syn0)
```


```{r}
# numpy arrays of zeros
syn1 <- np$zeros(c(5L, 10L))
print(syn1)
```

```{r}
# add a scalar to a numpy array
syn1 = syn1 + 0.1
print(syn1)
```

### Tuples (Python) and vectors (R)
In numpy a multidimensional array needs to be defined with a tuple
in R we do it with a vector.

In Python, we use a tuple, `(5, 5)`

```{python}
import numpy as np

print(np.ones((5, 5)))
```

In R, we use a vector `c(5L, 5L)`. The `L` indicates an integer.

```{r}
l1 <- np$ones(c(5L, 5L))
print(l1)
```

Vector-matrix multiplication in numpy:
```{r}
np$dot(syn0, syn1)
```

Build a numpy array from three R vectors:
```{r}
X <- np$array(rbind(c(1,2,3), c(4,5,6), c(7,8,9)))
print(X)
```

And transpose the array:
```{r}
np$transpose(X)
```

### Make a numpy array a tensor with `as_tensor()`

```{r}
a = np$array(list(1, 2, 3))   # a numpy array
t = torch$as_tensor(a)        # convert it to tensor
print(t)
```

We can create the tensor directly from R using `tensor()`:
```{r}
torch$tensor(list( 1,  2,  3))   # create a tensor
t[1L]$fill_(-1)                  # fill element with -1
print(a)
```


### Tensor to array, and viceversa
This is a very common operation in machine learning:

```{r}
# convert tensor to a numpy array
a = torch$rand(5L, 4L)
b = a$numpy()
print(b)
```

```{r}
# convert a numpy array to a tensor
np_a = np$array(c(c(3, 4), c(3, 6)))
t_a = torch$from_numpy(np_a)
print(t_a)
```


## Create tensors

A random 1D tensor:
```{r}
ft1 <- torch$FloatTensor(np$random$rand(5L))
print(ft1)
```

Force a tensor as a float of 64-bits:
```{r}
ft2 <- torch$as_tensor(np$random$rand(5L), dtype= torch$float64)
print(ft2)
```

Convert the tensor to float 16-bits:
```{r}
ft2_dbl <- torch$as_tensor(ft2, dtype = torch$float16)
ft2_dbl
```


Create a tensor of size (5 x 7) with uninitialized memory:

```{r}
a <- torch$FloatTensor(5L, 7L)
print(a)
```

Using arange to create a tensor. Start from 0:
```{r}
v = torch$arange(9L)
(v = v$view(3L, 3L))
```



## Tensor resizing

```{r}
x = torch$randn(2L, 3L)            # Size 2x3
y = x$view(6L)                     # Resize x to size 6
z = x$view(-1L, 2L)                # Size 3x2
print(y)
print(z)
```

Reproduce this tensor:

```
 0 1 2
 3 4 5
 6 7 8
``` 

```{r}
v = torch$arange(9L)
(v = v$view(3L, 3L))
```

### Concatenate tensors

```{r}
x = torch$randn(2L, 3L)
print(x)
```

Concatenate tensors by `dim=0`:
```{r}
torch$cat(list(x, x, x), 0L)
```


Concatenate tensors by `dim=1`:
```{r}
torch$cat(list(x, x, x), 1L)
```


## Reshape tensors

### With function `chunk()`:

Let's say this is an image tensor with the 3-channels and 28x28 pixels

```{r}
# ----- Reshape tensors -----
img <- torch$ones(3L, 28L, 28L)  # Create the tensor of ones
print(img$size())
```

On the first dimension `dim = 0L`, reshape the tensor:
```{r}
img_chunks <- torch$chunk(img, chunks = 3L, dim = 0L)
print(length(img_chunks))
```

The first chunk member:
```{r}
# 1st chunk member
img_chunk <- img_chunks[[1]]
print(img_chunk$size())
print(img_chunk$sum())      # if the tensor had all ones, what is the sum?
```

The second chunk member:
```{r}
# 2nd chunk member
img_chunk <- img_chunks[[2]]
print(img_chunk$size())
print(img_chunk$sum())        # if the tensor had all ones, what is the sum?
```

```{r}
# 3rd chunk member
img_chunk <- img_chunks[[3]]
print(img_chunk$size())
print(img_chunk$sum())        # if the tensor had all ones, what is the sum?
```


### With `index_select()`:

```{r}
img <- torch$ones(3L, 28L, 28L)  # Create the tensor of ones
```


This is the layer 1:
```{r}
# index_select. get layer 1
indices = torch$tensor(c(0L))
img_layer <- torch$index_select(img, dim = 0L, index = indices)
```

The size of the layer:
```{r}
print(img_layer$size())
```

The sum of all elements in that layer:
```{r}
print(img_layer$sum())
```


This is the layer 2:
```{r}
# index_select. get layer 2
indices = torch$tensor(c(1L))
img_layer <- torch$index_select(img, dim = 0L, index = indices)
print(img_layer$size())
print(img_layer$sum())
```


This is the layer 3:
```{r}
# index_select. get layer 3
indices = torch$tensor(c(2L))
img_layer <- torch$index_select(img, dim = 0L, index = indices)
print(img_layer$size())
print(img_layer$sum())
```



## Special tensors

### Identity matrix

```{r}
# identity matrix
eye = torch$eye(3L)              # Create an identity 3x3 tensor
print(eye)
```

### Ones

```{r}
(v = torch$ones(10L))              # A tensor of size 10 containing all ones
(v = torch$ones(2L, 1L, 2L, 1L))      # Size 2x1x2x1

```

```{r}
v = torch$ones_like(eye)     # A tensor with same shape as eye. Fill it with 1.
v
```

### Zeros

```{r}
(z = torch$zeros(10L))             # A tensor of size 10 containing all zeros
```


## Tensor fill

On this tensor:
```{r}
(v = torch$ones(3L, 3L))
```

Fill row 1 with 2s:
```{r}
v[1L, ]$fill_(2L)         
print(v)
```

Fill row 2 with 3s:
```{r}
v[2L, ]$fill_(3L)       
print(v)
```

```{r}
# Initialize Tensor with a range of value
v = torch$arange(10L)             # similar to range(5) but creating a Tensor
(v = torch$arange(0L, 10L, step = 1L))  # Size 5. Similar to range(0, 5, 1)
```


### Initialize a linear or log scale Tensor

Create a tensor with 10 linear points for (1, 10) inclusive:
```{r}
(v = torch$linspace(1L, 10L, steps = 10L)) 
```

Create a tensor with 10 logarithmic points for (1, 10) inclusive:
```{r}
(v = torch$logspace(start=-10L, end = 10L, steps = 5L)) 
```


### Inplace / Out-of-place

On this uninitialized tensor:
```{r}
(a <- torch$FloatTensor(5L, 7L))
```

Fill the tensor with the value 3.5:
```{r}
a$fill_(3.5)
```

Add a scalar to the tensor:
```{r}
b <- a$add(4.0)
```

The tensor `a` is still filled with 3.5.
A new tensor `b` is returned with values 3.5 + 4.0 = 7.5

```{r}
print(a)
print(b)
```



## Access to tensor elements

```{r}
# replace an element at position 0, 0
(new_tensor = torch$Tensor(list(list(1, 2), list(3, 4))))
```

Print element at position `1,1`:
```{r}
print(new_tensor[1L, 1L])
```

Fill element at position `1,1` with 5:
```{r}
new_tensor[1L, 1L]$fill_(5)
```

Show the modified tensor:
```{r}
print(new_tensor)   # tensor([[ 5.,  2.],[ 3.,  4.]])
```


Access an element at position `1, 0`:
```{r}
print(new_tensor[2L, 1L])           # tensor([ 3.])
print(new_tensor[2L, 1L]$item())    # 3.
```


### Using indices to access elements

On this tensor:
```{r}
x = torch$randn(3L, 4L)
print(x)
```

Select indices, `dim=0`:
```{r}
indices = torch$tensor(list(0L, 2L))
torch$index_select(x, 0L, indices)
```

Select indices, `dim=1`:
```{r}
torch$index_select(x, 1L, indices)
```


### Using the `take` function

```{r}
# Take by indices
src = torch$tensor(list(list(4, 3, 5),
                        list(6, 7, 8)) )
print(src)
print( torch$take(src, torch$tensor(list(0L, 2L, 5L))) )
```


## Other tensor operations

### Cross product
```{r}
m1 = torch$ones(3L, 5L)
m2 = torch$ones(3L, 5L)
v1 = torch$ones(3L)
# Cross product
# Size 3x5
(r = torch$cross(m1, m2))
```

### Dot product

```{r}
# Dot product of 2 tensors
# Dot product of 2 tensors

p <- torch$Tensor(list(4L, 2L))
q <- torch$Tensor(list(3L, 1L))                   

(r = torch$dot(p, q)) # 14
(r <- p %.*% q)
```


## Logical operations

```{r}
m0 = torch$zeros(3L, 5L)
m1 = torch$ones(3L, 5L)
m2 = torch$eye(3L, 5L)

print(m1 == m0)
```

```{r}
print(m1 != m1)
```

```{r}
print(m2 == m2)
```


```{r}
# AND
m1 & m1
```

```{r}
# OR
m0 | m2
```

```{r}
# OR
m1 | m2
```

```{r}
# all_boolean <- function(x) {
#   # convert tensor of 1s and 0s to a unique boolean
#   as.logical(torch$all(x)$numpy())
# }

# tensor is less than
A <- torch$ones(60000L, 1L, 28L, 28L)
C <- A * 0.5

# is C < A
all(torch$lt(C, A))
all(C < A)
# is A < C
all(A < C)
```

```{r}
# tensor is greater than
A <- torch$ones(60000L, 1L, 28L, 28L)
D <- A * 2.0
all(torch$gt(D, A))
all(torch$gt(A, D))
```


```{r}
# tensor is less than or equal
A1 <- torch$ones(60000L, 1L, 28L, 28L)
all(torch$le(A1, A1))
all(A1 <= A1)

# tensor is greater than or equal
A0 <- torch$zeros(60000L, 1L, 28L, 28L)
all(torch$ge(A0, A0))
all(A0 >= A0)

all(A1 >= A0)
all(A1 <= A0)
```

### Logical NOT

```{r}
all_true <- torch$BoolTensor(list(TRUE, TRUE, TRUE, TRUE))
all_true

# logical NOT
not_all_true <- !all_true
not_all_true
```

```{r}
diag <- torch$eye(5L)
diag

# logical NOT
not_diag <- !diag

# convert to integer
not_diag$to(dtype=torch$uint8)
```


## Distributions

Initialize a tensor randomized with a normal distribution with mean=0, var=1:

```{r}
a  <- torch$randn(5L, 7L)
print(a)
print(a$size())
```

### Uniform matrix

```{r}
library(rTorch)

# 3x5 matrix uniformly distributed between 0 and 1
mat0 <- torch$FloatTensor(3L, 5L)$uniform_(0L, 1L)

# fill a 3x5 matrix with 0.1
mat1 <- torch$FloatTensor(3L, 5L)$uniform_(0.1, 0.1)

# a vector with all ones
mat2 <- torch$FloatTensor(5L)$uniform_(1, 1)

mat0
mat1
```

### Binomial distribution

```{r}
Binomial <- torch$distributions$binomial$Binomial

m = Binomial(100, torch$tensor(list(0 , .2, .8, 1)))
(x = m$sample())
```

```{r}
m = Binomial(torch$tensor(list(list(5.), list(10.))), 
             torch$tensor(list(0.5, 0.8)))
(x = m$sample())
```

### Exponential distribution

```{r}
Exponential <- torch$distributions$exponential$Exponential

m = Exponential(torch$tensor(list(1.0)))
m$sample()  # Exponential distributed with rate=1
```

### Weibull distribution

```{r}
Weibull <- torch$distributions$weibull$Weibull

m = Weibull(torch$tensor(list(1.0)), torch$tensor(list(1.0)))
m$sample()  # sample from a Weibull distribution with scale=1, concentration=1

```

